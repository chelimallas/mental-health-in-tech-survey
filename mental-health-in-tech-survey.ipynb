{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":673,"sourceType":"datasetVersion","datasetId":311}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/chelimalla/mental-health-in-tech-survey?scriptVersionId=247554480\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-26T20:56:57.439343Z","iopub.execute_input":"2025-06-26T20:56:57.439709Z","iopub.status.idle":"2025-06-26T20:56:57.452886Z","shell.execute_reply.started":"2025-06-26T20:56:57.439682Z","shell.execute_reply":"2025-06-26T20:56:57.451788Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"\n    background-color: #f5f5dc; /* Beige background */\n    padding: 40px;\n    border-radius: 30px;\n    font-family: 'Times New Roman', Times, serif;\n    color: #2c2c2c;\n    box-shadow: 0 8px 20px rgba(0,0,0,0.08);\n    text-align: center;\n\">\n\n  <h1 style=\"\n      font-size: 50px; \n      color: #333333; \n      margin-bottom: 20px;\n  \">\n    Hello everyone!\n  </h1>\n\n  <p style=\"\n      font-size: 20px; \n      max-width: 800px; \n      margin: 0 auto 30px auto; \n      line-height: 1.7;\n      color: #4a4a4a;\n  \">\n    In today’s high-performance tech world, mental health often takes a backseat. From burnout to anxiety, the emotional toll of constant innovation and pressure is real. This project sheds light on how mental well-being intersects with the world of technology  and why it’s time we prioritized it.\n  </p>\n\n  <div style=\"\n      background-color: #e0e0d1; /* Soft neutral box */\n      color: #1a1a1a;\n      padding: 25px;\n      border-radius: 50px;\n      font-size: 18px;\n      max-width: 850px;\n      margin: 20px auto 0 auto;\n      line-height: 1.8;\n      box-shadow: 0 6px 12px rgba(0, 0, 0, 0.1);\n  \">\n    <strong>What is mental health?</strong><br><br>\n    Introduction\nMental health is a critical aspect of overall well-being and has increasingly become a focus of attention, particularly within high-stress professional environments such as the technology industry. In recent years, there has been a growing recognition of the impact that mental health issues such as anxiety, depression, and burnout can have on employee performance, job satisfaction, and workplace retention.\n\nDespite this awareness, many employees in the tech sector hesitate to seek treatment due to stigma, lack of resources, or workplace culture. As a result, early identification of individuals at risk becomes essential. Survey-based data collection offers valuable insights into mental health trends among tech workers. However, the high dimensionality and subjectivity of such data present analytical challenges.\n\nIn response to this, machine learning (ML) provides an effective approach to modeling and predicting mental health outcomes using structured survey data. By applying classification algorithms such as Logistic Regression, Random Forest, K-Nearest Neighbors (KNN), and Naive Bayes, researchers can uncover hidden patterns and develop tools for early intervention.\n\nThis project utilizes a public dataset from Kaggle, derived from a survey conducted by Open Sourcing Mental Illness (OSMI), to explore and classify individuals who have sought mental health treatment. It also evaluates the impact of dimensionality reduction using Principal Component Analysis (PCA) on model performance and visualization. The primary objective is to identify the most effective machine learning models for predicting treatment-seeking behavior, while also generating actionable insights into mental health risk factors in the tech workplace.\n  </div>\n\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"\n    background-color: #f5f5dc;\n    padding: 40px;\n    border-radius: 30px;\n    font-family: 'Times New Roman', Times, serif;\n    color: #2c2c2c;\n    box-shadow: 0 8px 20px rgba(0,0,0,0.08);\n    text-align: center;\n\">\n\n  <h2 style=\"\n      font-size: 38px;\n      color: #2e2e2e;\n      margin-bottom: 20px;\n  \">\n    Exploring Mental Health in Tech: A Machine Learning Approach\n  </h2>\n\n  <p style=\"\n      font-size: 20px;\n      max-width: 850px;\n      margin: 0 auto 30px auto;\n      line-height: 1.7;\n      color: #444;\n  \">\n    With mental health concerns rising across the tech industry, it's time to move beyond assumptions  and into data. Using a powerful mental health in tech dataset, this project takes a deep dive into the emotional well-being of developers, engineers, and IT professionals around the world.\n  </p>\n\n  <p style=\"\n      font-size: 20px;\n      max-width: 850px;\n      margin: 0 auto 30px auto;\n      line-height: 1.7;\n      color: #444;\n  \">\n    We approach this challenge as a classification problem  leveraging various machine learning models like <strong>Decision Tree (CART)</strong>, <strong>K-Nearest Neighbors (KNN)</strong>, <strong>Random Forest</strong>, and <strong>Naive Bayes</strong> to predict whether an individual is likely to seek mental health treatment or not.\n  </p>\n\n  <p style=\"\n      font-size: 20px;\n      max-width: 850px;\n      margin: 0 auto;\n      line-height: 1.7;\n      color: #444;\n  \">\n    Each model helps us identify critical features  from workplace support systems to personal attitudes  that influence mental health decisions in tech. The goal isn't just prediction. It's insight. It's action. It's awareness.\n  </p>\n\n  <hr style=\"margin: 40px auto; width: 60%; border: 0; height: 1px; background-color: #ccc;\">\n\n  <p style=\"\n      font-size: 18px;\n      color: #555;\n      margin-top: 10px;\n  \">\n    <em>Project by:</em><br>\n    <strong>Rishu Dixit</strong> | <strong>Sharvil Gad</strong> | <strong>Shashivadhan</strong> | <strong>Shravan</strong>\n  </p>\n\n</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"\n    background-color: #f5f5dc;\n    padding: 40px;\n    border-radius: 30px;\n    font-family: 'Times New Roman', Times, serif;\n    color: #2c2c2c;\n    box-shadow: 0 8px 20px rgba(0,0,0,0.08);\n    text-align: center;\n\">\n\n  <h2 style=\"\n      font-size: 38px;\n      color: #2e2e2e;\n      margin-bottom: 20px;\n  \">\n      Literature Review\n  </h2>\n\n  <p style=\"\n      font-size: 20px;\n      max-width: 850px;\n      margin: 0 auto 30px auto;\n      line-height: 1.7;\n      color: #444;\n  \">\n    \n\nMachine learning has been applied successfully to mental health datasets to classify and predict individuals at risk of mental illness. Algorithms such as Decision Trees, Random Forests, and K-Nearest Neighbors (KNN) have demonstrated promising results in identifying mental health issues based on survey data (Tiwari & Yadav, 2019). The dataset used in this project, sourced from Kaggle, contains responses from individuals in the tech industry regarding their mental health history, work environment, and support systems (Kaggle, 2017).\n\nDimensionality reduction techniques like Principal Component Analysis (PCA) have also been employed in mental health research to simplify complex survey data, reduce overfitting, and improve interpretability (Jolliffe & Cadima, 2016). While PCA may slightly reduce model accuracy, it can reveal hidden structure in the data and improve visualization of mental health clusters.\n\nThese studies emphasize that combining workplace mental health data with machine learning offers a powerful approach for identifying trends, providing support, and informing policy changes in tech environments.\n\n  </p>\n\n  <p style=\"\n      font-size: 20px;\n      max-width: 850px;\n      margin: 0 auto 30px auto;\n      line-height: 1.7;\n      color: #444;\n  \">\n    \n  </p>\n\n  <p style=\"\n      font-size: 20px;\n      max-width: 850px;\n      margin: 0 auto;\n      line-height: 1.7;\n      color: #444;\n  \">\n    \n\n  <hr style=\"margin: 40px auto; width: 60%; border: 0; height: 1px; background-color: #ccc;\">\n\n  <p style=\"\n      font-size: 18px;\n      color: #555;\n      margin-top: 10px;\n  \">\n    \n</div>","metadata":{}},{"cell_type":"markdown","source":"##  Predicting Mental Health Treatment in Tech Employees\n\n## 1. Dataset Description\n\n- **Source:** [Kaggle - Mental Health in Tech Survey](https://www.kaggle.com/datasets/osmi/mental-health-in-tech-survey)\n- **Target Variable:** `treatment` (Yes/No)\n- **Goal:** Predict whether a person has sought treatment for mental health issues based on workplace and demographic features.\n","metadata":{}},{"cell_type":"markdown","source":"##  STEP 1. Mental Health Classification Project: Library Imports and Setup\n\nThis notebook imports all the necessary Python libraries and modules required for a mental health classification project using machine learning. Each library serves a specific purpose, from data preprocessing and visualization to model training and evaluation.","metadata":{"execution":{"iopub.status.busy":"2025-06-26T17:36:30.929742Z","iopub.execute_input":"2025-06-26T17:36:30.930171Z","iopub.status.idle":"2025-06-26T17:36:36.483243Z","shell.execute_reply.started":"2025-06-26T17:36:30.930144Z","shell.execute_reply":"2025-06-26T17:36:36.482126Z"}}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_curve, auc\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay\nimport warnings\nwarnings.filterwarnings('ignore')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T20:56:57.45464Z","iopub.execute_input":"2025-06-26T20:56:57.454963Z","iopub.status.idle":"2025-06-26T20:56:57.474432Z","shell.execute_reply.started":"2025-06-26T20:56:57.454941Z","shell.execute_reply":"2025-06-26T20:56:57.473286Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## STEP 2. Load Dataset\n\nWe begin by loading the mental health survey dataset into a pandas DataFrame. This dataset contains information collected from a survey on mental health in the tech workplace.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/mental-health-in-tech-survey/survey.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T20:56:57.47553Z","iopub.execute_input":"2025-06-26T20:56:57.475899Z","iopub.status.idle":"2025-06-26T20:56:57.512779Z","shell.execute_reply.started":"2025-06-26T20:56:57.475864Z","shell.execute_reply":"2025-06-26T20:56:57.511743Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## STEP 3. Data Cleaning and Preprocessing\n\n Dropping Unnecessary Columns\n\nHandling Missing Values for Categorical Columns\n\nHandling Outliers and Missing Values in the Age Column\n\n","metadata":{}},{"cell_type":"code","source":"df.drop(['Timestamp', 'state', 'comments'], axis=1, inplace=True)\n\n# Fill missing values\nfor col in df.select_dtypes(include='object').columns:\n    df[col].fillna(df[col].mode()[0], inplace=True)\n\n# Handle outliers in Age\ndf['Age'] = df['Age'].apply(lambda x: np.nan if x < 10 or x > 100 else x)\ndf['Age'].fillna(df['Age'].median(), inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T20:56:57.51381Z","iopub.execute_input":"2025-06-26T20:56:57.514154Z","iopub.status.idle":"2025-06-26T20:56:57.540411Z","shell.execute_reply.started":"2025-06-26T20:56:57.514086Z","shell.execute_reply":"2025-06-26T20:56:57.538438Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## STEP 4.Encoding Categorical Variables","metadata":{}},{"cell_type":"code","source":"label_encoders = {}\nfor col in df.select_dtypes(include='object').columns:\n    le = LabelEncoder()\n    df[col] = le.fit_transform(df[col])\n    label_encoders[col] = le\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T20:56:57.54292Z","iopub.execute_input":"2025-06-26T20:56:57.54322Z","iopub.status.idle":"2025-06-26T20:56:57.573669Z","shell.execute_reply.started":"2025-06-26T20:56:57.543195Z","shell.execute_reply":"2025-06-26T20:56:57.572674Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## STEP 5 Preparing Data for Machine Learning\n\n### 1: Separate Features and Target Variable\n `X` contains all input features except the target.\n `y` contains the target variable `treatment` (whether mental health treatment was sought).\n\n###  2: Feature Scaling\n Standardize features with `StandardScaler` to mean 0 and variance 1.\n This is important for algorithms sensitive to feature scale (e.g., KNN, Logistic Regression).\n\n###  3: Train-Test Split\n Split data into 80% training and 20% testing sets.\n `random_state=42` ensures reproducibility.\n\n\n","metadata":{}},{"cell_type":"code","source":"# Separate features and target\nX = df.drop('treatment', axis=1)\ny = df['treatment']\n\n# Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X_scaled, y, test_size=0.2, random_state=42\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T20:56:57.574751Z","iopub.execute_input":"2025-06-26T20:56:57.575062Z","iopub.status.idle":"2025-06-26T20:56:57.58983Z","shell.execute_reply.started":"2025-06-26T20:56:57.57503Z","shell.execute_reply":"2025-06-26T20:56:57.588714Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## STEP 6. Model Training, Evaluation, and Visualization\n\n### 1. Define Models\n\n We initialize five classification models:\n   Decision Tree\n   K-Nearest Neighbors (KNN)\n   Random Forest\n   Naive Bayes (Gaussian)\n   Logistic Regression\n\n### 2. Setup Cross-Validation\n\n Use **StratifiedKFold** with 5 splits to maintain balanced class distribution during cross-validation.\n This provides a more reliable estimate of model performance.\n\n### 3. Model Training & Evaluation Loop\n\nFor each model:\n Perform **cross-validation** on the full scaled dataset and calculate mean accuracy.\n Fit the model on the training set (`X_train`, `y_train`).\n Predict on the test set (`X_test`).\n Calculate evaluation metrics:\n   Accuracy\n   Precision\n   Recall\n   F1 Score\n Append results for comparison.\n Print a detailed **classification report** showing precision, recall, f1-score per class.\n\n### 4. Visualizations Per Model\n\n **KNN**: Scatter plot of predictions on the first two principal features colored by predicted class to visualize clusters.\n **Decision Tree**: Visual tree diagram showing splits up to depth 2, highlighting decision rules.\n **Logistic Regression**: ROC curve with Area Under the Curve (AUC) to evaluate classifier performance.\n **Other models** (Random Forest, Naive Bayes): Confusion matrix heatmap to show true vs predicted class distribution.\n\n\n### Summary\n\nThis approach combines robust cross-validation with detailed test-set evaluation and visualization, helping you compare model strengths and weaknesses effectively.\n\n\n","metadata":{}},{"cell_type":"code","source":"models = {\n    'Decision Tree': DecisionTreeClassifier(),\n    'KNN': KNeighborsClassifier(),\n    'Random Forest': RandomForestClassifier(),\n    'Naive Bayes': GaussianNB(),\n    'Logistic Regression': LogisticRegression()\n}\n\nresults = []\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor name, model in models.items():\n    # Cross-validation accuracy scores\n    scores = cross_val_score(model, X_scaled, y, cv=skf, scoring='accuracy')\n    \n    # Fit model on training data\n    model.fit(X_train, y_train)\n    \n    # Predict on test data\n    y_pred = model.predict(X_test)\n    \n    # Calculate evaluation metrics\n    acc = accuracy_score(y_test, y_pred)\n    prec = precision_score(y_test, y_pred)\n    rec = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    \n    results.append([name, acc, prec, rec, f1, scores.mean()])\n    \n    # Print classification report\n    print(f\"\\n{name} Evaluation:\")\n    print(classification_report(y_test, y_pred))\n    \n    # Visualization based on model type\n    if name == \"KNN\":\n        plt.figure(figsize=(6,4))\n        sns.scatterplot(x=X_test[:, 0], y=X_test[:, 1], hue=y_pred, palette='coolwarm', alpha=0.6)\n        plt.title(\"KNN Prediction Clusters\")\n        plt.xlabel(\"Feature 1\")\n        plt.ylabel(\"Feature 2\")\n        plt.show()\n        \n    elif name == \"Decision Tree\":\n        plt.figure(figsize=(12,6))\n        plot_tree(model, feature_names=X.columns, class_names=['No', 'Yes'], filled=True, max_depth=2)\n        plt.title(\"Decision Tree Visualization\")\n        plt.show()\n        \n    elif name == \"Logistic Regression\":\n        fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n        roc_auc = auc(fpr, tpr)\n        plt.figure()\n        plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n        plt.plot([0, 1], [0, 1], 'k--')\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('ROC Curve - Logistic Regression')\n        plt.legend(loc=\"lower right\")\n        plt.show()\n        \n    else:\n        ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, cmap='Blues')\n        plt.title(f\"{name} Confusion Matrix\")\n        plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T20:56:57.591122Z","iopub.execute_input":"2025-06-26T20:56:57.5915Z","iopub.status.idle":"2025-06-26T20:57:00.976439Z","shell.execute_reply.started":"2025-06-26T20:56:57.591462Z","shell.execute_reply":"2025-06-26T20:57:00.975544Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## STEP 7. Model Performance Summary\n\n Convert the collected evaluation metrics stored in `results` into a pandas DataFrame for better readability.\n \n Columns include:\n \n   **Model:** Name of the classifier\n   \n   **Accuracy:** Test set accuracy\n   \n   **Precision:** Test set precision\n   \n   **Recall:** Test set recall\n   \n   **F1-Score:** Test set F1 score\n   \n   **CV Accuracy:** Mean cross-validation accuracy\n  \n\n","metadata":{}},{"cell_type":"code","source":"results_df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'CV Accuracy'])\nprint(\"\\nModel Comparison:\")\nprint(results_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T20:57:00.977484Z","iopub.execute_input":"2025-06-26T20:57:00.977854Z","iopub.status.idle":"2025-06-26T20:57:00.987743Z","shell.execute_reply.started":"2025-06-26T20:57:00.977824Z","shell.execute_reply":"2025-06-26T20:57:00.986411Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## STEP 8. Principal Component Analysis (PCA) and Visualization\n\n### 1. Dimensionality Reduction\n **PCA** reduces the feature space to **2 principal components** capturing the maximum variance.\n This helps visualize high-dimensional data in 2D.\n\n### 2. Train-Test Split on PCA Data\n Split the transformed dataset into training and testing subsets for further modeling if needed.\n\n### 3. Explained Variance Ratio\n Prints how much variance each principal component captures.\n Useful to understand how well PCA summarizes the data.\n\n### 4. Visualization\n A scatter plot of the two principal components.\n Points are colored by the target variable (`treatment`).\n This plot helps to visually assess if classes are separable in the reduced space.\n\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\n# Apply PCA to reduce features to 2 principal components\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n# Split the PCA-transformed data into train and test sets\nX_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(\n    X_pca, y, test_size=0.2, random_state=42\n)\n\n# Print variance explained by each principal component\nprint(\"\\nPCA Explained Variance Ratio:\", pca.explained_variance_ratio_)\n\n# Visualize the PCA components colored by treatment target\nplt.figure(figsize=(8,6))\nsns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=y, palette='viridis', s=50)\nplt.title('PCA Projection with Hue by Treatment')\nplt.xlabel('PCA 1')\nplt.ylabel('PCA 2')\nplt.legend(title='Treatment')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T20:57:00.988923Z","iopub.execute_input":"2025-06-26T20:57:00.989247Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## STEP 9. Model Training and Evaluation on PCA-Reduced Data\n\n### 1. Model Training and Prediction\n Train each model using the **PCA-transformed training data** (`X_train_pca`, `y_train_pca`).\n Predict labels on the **PCA-transformed test set** (`X_test_pca`).\n\n### 2. Evaluation Metrics\n Calculate key performance metrics on the test set:\n   Accuracy\n   Precision\n   Recall\n   F1 Score\n\n### 3. Visualization for Each Model\n **Logistic Regression:** ROC curve with AUC to assess classification performance.\n **Decision Tree:** Heatmap of confusion matrix to visualize prediction errors.\n **KNN:** Scatter plot of PCA components colored by predicted class to show clustering.\n **Other Models (Random Forest, Naive Bayes):** Confusion matrix plots for visual error analysis.\n\n\n\n### Summary\n\nThis workflow allows you to compare model performances **before and after dimensionality reduction** using PCA, helping to understand the impact of feature reduction on classification results.\n\n","metadata":{}},{"cell_type":"code","source":"results_pca = []\n\nfor name, model in models.items():\n    model.fit(X_train_pca, y_train_pca)\n    y_pred_pca = model.predict(X_test_pca)\n    \n    acc = accuracy_score(y_test_pca, y_pred_pca)\n    prec = precision_score(y_test_pca, y_pred_pca)\n    rec = recall_score(y_test_pca, y_pred_pca)\n    f1 = f1_score(y_test_pca, y_pred_pca)\n    \n    results_pca.append([name, acc, prec, rec, f1])\n    \n    print(f\"\\n{name} PCA Evaluation:\")\n    \n    # Visuals\n    if name == \"Logistic Regression\":\n        fpr, tpr, _ = roc_curve(y_test_pca, model.predict_proba(X_test_pca)[:,1])\n        roc_auc = auc(fpr, tpr)\n        plt.figure()\n        plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n        plt.plot([0, 1], [0, 1], 'k--')\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('PCA ROC - Logistic Regression')\n        plt.legend()\n        plt.show()\n    elif name == \"Decision Tree\":\n        plt.figure(figsize=(8, 4))\n        sns.heatmap(confusion_matrix(y_test_pca, y_pred_pca), annot=True, fmt='d', cmap='Purples')\n        plt.title(\"Decision Tree Confusion Matrix (PCA)\")\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Actual\")\n        plt.show()\n    elif name == \"KNN\":\n        plt.figure(figsize=(6,6))\n        sns.scatterplot(x=X_test_pca[:,0], y=X_test_pca[:,1], hue=y_pred_pca, palette='coolwarm')\n        plt.title(\"KNN PCA Prediction Clusters\")\n        plt.xlabel(\"PCA 1\")\n        plt.ylabel(\"PCA 2\")\n        plt.show()\n    else:\n        ConfusionMatrixDisplay.from_predictions(y_test_pca, y_pred_pca, cmap='Greens')\n        plt.title(f\"{name} Confusion Matrix (PCA)\")\n        plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.idle":"2025-06-26T20:57:02.633415Z","shell.execute_reply.started":"2025-06-26T20:57:01.32893Z","shell.execute_reply":"2025-06-26T20:57:02.632232Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## STEP 10. Model Performance Summary After PCA\n\n Convert the list `results_pca` into a pandas DataFrame for clearer presentation.\n Columns include key classification metrics:\n \n   **Model** — Name of the classifier\n   \n   **Accuracy** — Test set accuracy after PCA\n   \n   **Precision** — Test set precision after PCA\n   \n   **Recall** — Test set recall after PCA\n   \n   **F1-Score** — Test set F1-score after PCA\n\n","metadata":{}},{"cell_type":"code","source":"results_pca_df = pd.DataFrame(results_pca, columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])\nprint(\"\\nModel Comparison after PCA:\")\nprint(results_pca_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T20:57:02.63474Z","iopub.execute_input":"2025-06-26T20:57:02.6351Z","iopub.status.idle":"2025-06-26T20:57:02.643748Z","shell.execute_reply.started":"2025-06-26T20:57:02.635065Z","shell.execute_reply":"2025-06-26T20:57:02.642754Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## STEP 11 Accuracy Comparison: Original Data vs PCA-Reduced Data\n\n- **Purpose:** Visualize how applying PCA affects the accuracy of different classification models.\n- Two bar charts side-by-side for each model:\n  - **Original:** Accuracy using all features.\n  - **PCA:** Accuracy using only the top 2 principal components.\n- **X-axis:** Model names.\n- **Y-axis:** Accuracy scores.\n- The plot helps quickly assess whether dimensionality reduction improved or degraded model performance.\n\n","metadata":{"execution":{"iopub.status.busy":"2025-06-26T18:04:34.061952Z","iopub.execute_input":"2025-06-26T18:04:34.062282Z","iopub.status.idle":"2025-06-26T18:04:34.070111Z","shell.execute_reply.started":"2025-06-26T18:04:34.062261Z","shell.execute_reply":"2025-06-26T18:04:34.068528Z"}}},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nx = np.arange(len(results_pca_df['Model']))\nwidth = 0.35\n\nplt.bar(x - width/2, results_df['Accuracy'], width, label='Original')\nplt.bar(x + width/2, results_pca_df['Accuracy'], width, label='PCA')\n\nplt.xticks(x, results_df['Model'])\nplt.ylabel(\"Accuracy\")\nplt.title(\"Accuracy Comparison Before and After PCA\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T20:57:02.64497Z","iopub.execute_input":"2025-06-26T20:57:02.645252Z","iopub.status.idle":"2025-06-26T20:57:02.897026Z","shell.execute_reply.started":"2025-06-26T20:57:02.645231Z","shell.execute_reply":"2025-06-26T20:57:02.896011Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  Key Observations\n\n **Random Forest** performed best before applying PCA.\n Accuracy generally **dropped after PCA** due to dimensionality reduction.\n PCA is highly useful for **visualizing clusters** and understanding data structure.\n When **accuracy is a priority**, it is better to use the **full feature set**.\n PCA helps reduce **computational load** and improves **interpretability** for visualization tasks.\n","metadata":{}},{"cell_type":"markdown","source":" ## References\nJolliffe, I. T., & Cadima, J. (2016). Principal component analysis: A review and recent developments. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 374(2065), 20150202. https://doi.org/10.1098/rsta.2015.0202\n\nKaggle. (2017). Mental Health in Tech Survey. Retrieved from https://www.kaggle.com/osmi/mental-health-in-tech-survey\n\nSharma, A., & Dhar, R. L. (2016). Factors influencing job performance of software developers in Indian IT sector: A path model. Journal of Organizational Change Management, 29(3), 407–429.\n\nTiwari, R., & Yadav, V. (2019). Predicting psychological disorders using machine learning techniques. Procedia Computer Science, 152, 202–211. https://doi.org/10.1016/j.procs.2019.05.014","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}